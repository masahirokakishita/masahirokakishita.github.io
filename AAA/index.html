<!DOCTYPE html>
<html>
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<meta http-equiv="Content-Script-Type" content="text/javascript">
	<script type="text/javascript" src="peak.js"></script>
	<script type="text/javascript" src="fft.js"></script>
	<script type="text/javascript" src="drawgraph.js"></script>
	<script type="text/javascript" src="dpmsub.js"></script>
	<script type="text/javascript" src="gsub.js"></script>
	<title>HSD2</title>

  <style type="text/css">
    <!--
    #sans { color: black; font-family:sans-serif ;  font-size: 10pt; line-height : 1.5em}
    #mono { color: black; font-family:monospace ; font-size: 10pt; line-height : 1.5em}
    #log { }
    -->
    </style>


<script>
{
	var WINDOW_SIZE=1024;
	var WINDOW_HSIZE=WINDOW_SIZE/2;
	var WINDOW_MSIZE=WINDOW_SIZE/4;
}

{
	var audioContext = new AudioContext();
	var audiosource;
	var splitter = audioContext.createChannelSplitter(2);
	var merger = audioContext.createChannelMerger(2);
	var node = audioContext.createScriptProcessor(WINDOW_SIZE, 2, 2);

	// Gain Node for both channel
 	var gainL = audioContext.createGain();
	var gainR = audioContext.createGain();
	gainL.gain.value = 1.0;
	gainR.gain.value = 1.0;

	navigator.getUserMedia = ( navigator.getUserMedia ||
		navigator.webkitGetUserMedia ||
		navigator.mozGetUserMedia ||
		navigator.msGetUserMedia);

	function soundThrough() {
		navigator.getUserMedia({video: false, audio: true},
			function(stream){
				audiosource = audioContext.createMediaStreamSource(stream);
				audiosource.connect(node);
				node.connect(splitter);
				splitter.connect(gainL, 0);
				splitter.connect(gainR, 1);
				gainL.connect(merger, 0, 0)
				gainR.connect(merger, 0, 1)
				merger.connect(audioContext.destination);
			},
			function(e) {	// I can't use getUserMedia
				console.log(e);
			}
		);
	}
}
</script>


<hr>
</HEAD>

<body onload="soundThrough();" bgcolor="#ffffff" text="#000000" link="#0000ff" vlink="#ff00ff" alink="#ff0000" style="margin-right:28px;margin-left:28px;margin-top:20px;">
<br>
<center><h2>HSD TRYAL<h2></center>

<!--	-------------------------------------------------------------------- -->
<center>
<canvas id="waveshape" width="2048" height="240">
</canvas>
<br>
<canvas id="bkg" width="2048" height="240"></canvas>
</center>

<pre id="log">
</pre>

<!--	------------------------------------------------------------------ -->
<script>
{
	var ixb = 12;			//描画X軸の基点
	var iyb = 12;			//描画Y軸の基点
	var ixw = WINDOW_SIZE;	//描画のX軸のサイズ
	var iyw = 200;			//描画のX軸のサイズ
	var drf = 1;
	var ncnt=16;

	/* 描画領域の初期化 */
	var canvas = document.getElementById('waveshape');
	var waveshape = canvas.getContext('2d');
    waveshape.strokeRect(ixb,iyb,ixw,iyw);

	/* Audio Buffer が一杯になったらこの関数が呼ばれる */
	function process2(data){
		var procsize = data.inputBuffer.length;
		/* L-ch を描画する */
		var inbufL = data.inputBuffer.getChannelData(0);
		var inbufR = data.inputBuffer.getChannelData(1);
		var outbufL = data.outputBuffer.getChannelData(0);
		var outbufR = data.outputBuffer.getChannelData(1);
		for(var i=0; i<procsize; i++){ outbufL[i]=inbufL[i]; outbufR[i]=inbufR[i]; }
	}

	var inbufL = null;
	var inbufR = null;
	var outbufL = null;
	var outbufR = null;

	function process(data){
		var procsize = data.inputBuffer.length;
		/* L-ch を描画する */
		inbufL = data.inputBuffer.getChannelData(0);
		inbufR = data.inputBuffer.getChannelData(1);
		outbufL = data.outputBuffer.getChannelData(0);
		outbufR = data.outputBuffer.getChannelData(1);

		for(var i=0; i<procsize; i++){ 
			outbufL[i]=inbufL[i]; 
			outbufR[i]=inbufR[i]; 
			mData[iwpoint++]=outbufL[i];
		}
		iwpoint%=(WINDOW_SIZE*4);

		fdg1.fClearWindowInside();
		for(i=0; i<WINDOW_SIZE; i++) mImage[i]=0;

		//スレショルドを超えたらFFTする。
		for(i=0; i<WINDOW_SIZE; i++){
			mReal[i]=inbufL[i]*16;
		}

		transform(mReal, mImage);

		var pavr=0;
		for(i=1; i<WINDOW_HSIZE; i++){
			pw = mReal[i]*mReal[i]+mImage[i]*mImage[i];
			if(pw<=0) mPower[i]=0.;
			else mPower[i]=10.*Math.log(pw)/Math.log(10.);
			pavr+=mPower[i];
		}

		if(drf){
			waveshape.beginPath();
			var ix=iy=0;
			wavedraw(inbufL,procsize);
			wavfft();
		} else {

		}

	}

	//データ処理関数の定義
	node.onaudioprocess=process;

	/* LOG領域の初期化 */
	var log = document.getElementById("log");
	var sampleRate = audioContext.sampleRate;

	log.innerText +="sample rate:"
	log.innerText += sampleRate;
	log.innerText +="\n";

	function leftGainChange(value){
		log.innerText +="left gain:"
		log.innerText +=value;
		log.innerText +="\n";
		gainL.gain.value = value;
	}
	function RightGainChange(value){
		log.innerText +="right gain:"
		log.innerText +=value;
		log.innerText +="\n";
		gainR.gain.value = value;
	}
}
</script>

<form method="volume">
LEFT &nbsp;&nbsp;GAIN: <input type="number" name="left"  step="0.1" min="0.0" max="1.0" value="1.0" onchange="leftGainChange(this.value);"><br>
RIGHT GAIN: <input type="number" name="right" step="0.1" min="0.0" max="1.0" value="1.0" onchange="RightGainChange(this.value);">
</form>
<input type="button" value="REC REF1" onclick="recref1()">
</body>
<script>
	var recpeak1=[];
	var recmag1=[];
	var mDist=Array(WINDOW_HSIZE);
	var mjj=0;
	var icnt=0;

	for(var i=0; i<WINDOW_HSIZE; i++){ mDist[i] = 0; } 
	var dDist=0;

function recref1()
{
	if(drf){
		drf=0;
		fdg1.fClearWindowInside();
		for(i=0; i<WINDOW_SIZE; i++) mImage[i]=0;
		for(i=0; i<WINDOW_SIZE; i++){
			mReal[i]=mWin[i]*inbufL[i]*16;
		}
		transform(mReal, mImage);

		var pavr=0;
		for(i=1; i<WINDOW_HSIZE; i++){
			pw = mReal[i]*mReal[i]+mImage[i]*mImage[i];
			if(pw<=0) mPower[i]=0.;
			else mPower[i]=10.*Math.log(pw)/Math.log(10.);
			pavr+=mPower[i];
		}
		pavr/=WINDOW_HSIZE;
		console.log(pavr);

		fdg1.fSetViewPort(0,WINDOW_HSIZE,0,80.0);
		fdg1.fDrawLine(mPower);

		log.innerText ="\n";
		var pp=0;
		var i=0;
		var pfreq;
		var cent;
		
		recpeak1=[];
		recmag1=[];

		while((pp=nextMaxPeak(mPower,WINDOW_MSIZE,pp))!=-1){
			if(mPower[pp]>pavr+30){
				pfreq = pp*sampleRate/WINDOW_SIZE;
				cent = 1200.*Math.log(pfreq)/Math.log(2.)
				log.innerText +=pfreq;
				log.innerText +="  ";
				log.innerText +=cent;
				log.innerText +="  ";
				log.innerText +=mPower[pp];
				log.innerText +="\n";
				recpeak1[i]= cent;
				recmag1[i]= mPower[pp];
				i++;
			}
		}
		icnt=i;
		console.log(icnt);


	} else drf=1;
}
</script>

<script>
	var ixb = 100;	//描画X軸の基点
	var iyb = 12;	//描画Y軸の基点
	var ixw = 1124;	//描画のX軸のサイズ
	var iyw = 212;	//描画のX軸のサイズ

	/* 描画領域の初期化 */
	var fdg1 = new DrawGraph(ixb,ixw,iyb,iyw);
	fdg1.fSetCanvas(document.getElementById('bkg'));
	fdg1.fSetViewPort(0,WINDOW_SIZE,-1.0,1.0);
//	fdg1.fStrokeRect();

	var mReal=new Array(WINDOW_SIZE);
	var mData=new Array(WINDOW_SIZE*4);
	var mImage=new Array(WINDOW_SIZE);
	var mWin=new Array(WINDOW_SIZE);
	var mPower=new Array(WINDOW_HSIZE);
	var iwpoint=0;
	var pavr=0;

	for(i=0; i<WINDOW_SIZE; i++){
		mWin[i] = 0.5-0.5*Math.cos(2.*Math.PI*i/(WINDOW_SIZE-1));
	}

	fdg1.fSetViewPort(0,WINDOW_HSIZE,0,1.0,0);
	fdg1.fDrawLine(mWin);

</script>
</html>

